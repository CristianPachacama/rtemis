% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rtset.R
\name{rtset.MXN}
\alias{rtset.MXN}
\title{\code{rtset.MXN}: Set parameters for \link{s.MXN}}
\usage{
rtset.MXN(n.hidden.nodes = NULL, output = NULL, activation = "relu",
  ctx = mxnet::mx.cpu(), optimizer = "sgd",
  initializer = mxnet::mx.init.Xavier(), batch.size = NULL,
  momentum = 0.9, max.epochs = 2000, min.epochs = 25,
  early.stop = "train", early.stop.n.steps = NULL,
  early.stop.relativeVariance.threshold = NULL, learning.rate = NULL,
  dropout = 0, dropout.before = 1, dropout.after = 0,
  eval.metric = NULL, arg.params = NULL, mx.seed = NULL)
}
\arguments{
\item{n.hidden.nodes}{Integer vector: Length must be equal to the number of hidden layers you wish to create}

\item{output}{String: "Logistic" for binary classification, "Softmax" for classification of 2 or more classes,
"Linear" for Regression. Defaults to "Logistic" for binary outcome, "Softmax" for 3+ classes, "LinearReg" for
regression.}

\item{activation}{String vector: Activation types to use: 'relu', 'sigmoid', 'softrelu', 'tanh'.
If length < n of hidden layers, elements are recycled. See \code{mxnet::mx.symbol.Activation}}

\item{ctx}{MXNET context: \code{mxnet::mx.cpu()} to use CPU(s). Define N of cores using \code{n.cores} argument.
\code{mxnet::mx.gpu()} to use GPU. For multiple GPUs, provide list like such:
\code{ctx = list(mxnet::mx.gpu(0), mxnet::mx.gpu(1)} to use two GPUs.}

\item{max.epochs}{Integer: Number of iterations for training.}

\item{learning.rate}{Float: learning rate}

\item{dropout}{Float (0, 1): Probability of dropping nodes}

\item{dropout.before}{Integer: Index of hidden layer before which dropout should be applied}

\item{dropout.after}{Integer: Index of hidden layer after which dropout should be applied}

\item{eval.metric}{String: Metrix used for evaluation during train. Default: "rmse"}
}
\description{
\code{rtset.MXN}: Set parameters for \link{s.MXN}
}
